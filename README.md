# Yale Predoc Reading Group

Welcome to the Yale Predoc Reading Group. This is a group for Yale Tobin Pre-Doctoral Fellows (and related Pre-Doctoral Fellows) to meet and discuss public policy (and closely related) papers.

To suggest a future paper please visit this link: <a href="https://forms.office.com/r/S4EVZz7kC9"> https://forms.office.com/r/S4EVZz7kC9 </a>

To vote on a paper for next week please visit this link: <a href="https://forms.office.com/r/evFZ4CVa8v"> https://forms.office.com/r/evFZ4CVa8v </a>

## Current Paper:

## Upcoming Papers:

## Proposed Papers:

#### <a href="https://web.stanford.edu/~gentzkow/research/BayesianPersuasion.pdf">Bayesian Persuasion</a>
##### Emir Kamenica and Matthew Gentzkow

<b> Abstract: </b> When is it possible for one person to persuade another to change her action? We consider a symmetric information model where a sender chooses a signal to reveal to a receiver, who then takes a noncon- tractible action that affects the welfare of both players. We derive necessary and sufficient conditions for the existence of a signal that strictly benefits the sender. We characterize sender-optimal signals. We examine comparative statics with respect to the alignment of the sender’s and the receiver’s preferences. Finally, we apply our results to persuasion by litigators, lobbyists, and salespeople.

#### <a href= "https://davidcard.berkeley.edu/papers/mariel-impact.pdf">The Impact of the Mariel Boatlift on the Miami Labor Market</a>
##### David Card

<b> Abstract: </b> Using data from the Current Population Survey, this paper describes the effect of the Marie1Boatlift of 1980on the Miami labor market. The Marie1 immigrants increased the Miami labor force by 7%, and the percentage increase in labor supply to less-skilled occupations and industries was even greater because most of the immigrants were relatively unskilled. Nevertheless, the Marie1 influx appears to have had virtually no effect on the wages or unemployment rates of less-skilled workers, even among Cubans who had immigrated earlier. The author suggests that the ability of Miami's labor market to rapidly absorb the Marie1 immigrants was largely owing to its adjustment to other lar

#### <a href= "https://arxiv.org/pdf/2403.18694"> Designing Simple Mechanisms </a>
##### Shengwu Li

<b> Abstract: </b> Which mechanisms are simple to play? When is it easy for participants to see that a mechanism is incentive-compatible? I will start by explaining how and why economists came to ask these questions. Then I will discuss three recent answers, that capture different aspects of what makes a mechanism simple.

#### <a href= "http://www.math.huji.ac.il/raumann/pdf/Agreeing%20to%20Disagree.pdf"> Agree to Disagree </a>
##### Robert J. Aumann

<b> Abstract: </b> Two people, 1 and 2, are said to have common knowledge of an event E if both know it, 1 knows that 2 knows it, 2 knows that 1 knows is, 1 knows that 2 knows that 1 knows it, and so on. THEOREM. If two people have the same priors, and their posteriors for an event A are common knowledge, then these posteriors are equal.

#### <a href= "https://pubs.aeaweb.org/doi/pdfplus/10.1257/pol.20200295"> The Labor Market for Teachers under Different Pay Schemes </a>
##### Barbara Biasi

<b> Abstract: </b> Compensation of most US public school teachers is rigid and solely
based on seniority. This paper studies the effects of a reform that gave school districts in Wisconsin full autonomy to redesign teacher pay schemes. Following the reform some districts switched to flexible compensation. Using the expiration of preexisting collective bargaining agreements as a source of exogenous variation in the timing of changes in pay, I show that the introduction of flexible pay raised salaries of high-quality teachers, increased teacher quality (due to the arrival of high-quality teachers from other districts and increased effort), and improved student achievement.

#### <a href= "https://pubs.aeaweb.org/doi/pdfplus/10.1257/app.20160089"> Social Media and Corruption </a>
##### Ruben Enikolopov, Maria Petrova, and Konstantin Sonin

<b> Abstract: </b> Does new media promote accountability in nondemocratic countries, where offline media is often suppressed? We show that blog posts, which exposed corruption in Russian state-controlled companies, had
a negative causal impact on their market returns. For identification, we exploit the precise timing of blog posts by looking at within-day results with company-day fixed effects. Furthermore, we show that the posts are ultimately associated with higher management turnover and less minority shareholder conflicts. Taken together, our results suggest that social media can discipline corruption even in a country with limited political competition and heavily censored traditional media. 

#### <a href= "https://pubs.aeaweb.org/doi/pdfplus/10.1257/app.20160089"> Letting Old Data Speak: Local Cultural Traits in Qing Dynasty China Grain Prices </a>
##### T. Terry Cheung, Shaowen Luo, Kwok Ping Tsang

<b> Abstract: </b> We investigate the persistent impact of data misreporting from China’s Qing Dynasty
(1644-1912) on contemporary data quality in the country. We examine historical grain price data,
collected monthly by Qing prefectural officials and reported to the central government. Using the
absence of seasonal price fluctuations over extended periods as an indicator, we assess data quality.
Employing an instrumental variable approach, we establish a causal link between data quality in the
Qing Dynasty and data misreporting in modern China. Our findings indicate that a one-standarddeviation increase in Qing data quality corresponds to a 0.16 standard deviation increase in modern data quality. This result holds under various alternative specifications, even when the analysis is limited to frequently traded major crop types from the Qing Dynasty and when different periods of modern data quality are used. Moreover, we find that the persistence of data misreporting remains evident even in prefectures that have undergone significant changes in geographical attributes. We further suggest that this persistent pattern of data misreporting is primarily influenced by cultural factors rather than geographical ones.

#### <a href= "https://journals.sagepub.com/doi/10.1177/1527002517717299"> The Effects of Physical Activity on Social Interactions: The Case of Trust and Trustworthiness </a>
##### Giovanni Di Bartolomeo and Stefano Papa

<b> Abstract: </b> There is no doubt that physical activity improves health conditions; however, does it also affect the way people interact? Beyond the obvious effects related to team games, we wonder whether physical activity has in itself some effect on social behavior. Our research focuses on the potential effects of physical activity on trust and trustworthiness. Specifically, we compare the choices of subjects playing an investment game who were previously exposed to short-time physical activity to others who are not exposed to it, but involved in different simple tasks. On average, we find that subjects exposed to physical activity exhibit more trust and prosocial behaviors than those who are not exposed. These effects are not temporary.

#### <a href= "https://onlinelibrary.wiley.com/doi/full/10.1111/j.1468-0289.2009.00483.x#fn1"> Girl power: the European marriage pattern and labour markets in the North Sea region in the late medieval and early modern period </a>
##### Tine De Moor and Jan Luiten Van Zanden

<b> Abstract: </b> This article argues that the European Marriage Pattern (EMP) has played a fundamental role in western Europe’s economic development. The EMP emerged in north-western Europe in the late medieval period as a result of the preaching of the Catholic Church promoting marriage based on consensus, the rise of labour markets, and specific institutions concerning property transfers between generations that encouraged wage labour by women. It resulted in a demographic regime embedded in a highly commercial environment, in which households interacted frequently with labour, capital, and commodity markets.We also discuss possible long-term consequences for human capital formation and institution building.

#### <a href= "https://www.aeaweb.org/articles?id=10.1257/jep.32.1.3"> The Economic Implications of Housing Supply </a>
##### Edward Glaeser and Joseph Gyourko

<b> Abstract: </b> In this essay, we review the basic economics of housing supply and the functioning of US housing markets to better understand the distribution of home prices, household wealth, and the spatial distribution of people across markets. We employ a cost-based approach to gauge whether a housing market is delivering appropriately priced units. Specifically, we investigate whether market prices (roughly) equal the costs of producing the housing unit. If so, the market is well-functioning in the sense that it efficiently delivers housing units at their production cost. The gap between price and production cost can be understood as a regulatory tax. The available evidence suggests, but does not definitively prove, that the implicit tax on development created by housing regulations is higher in many areas than any reasonable negative externalities associated with new construction. We discuss two main effects of developments in housing prices: on patterns of household wealth and on the incentives for relocation to high-wage, high-productivity areas. Finally, we turn to policy implications.

#### <a href= "https://www.aeaweb.org/articles?id=10.1257/aer.20181289"> The Effects of Rent Control Expansion on Tenants, Landlords, and Inequality: Evidence from San Francisco </a>
##### Rebecca Diamond, Tim McQuade, and Franklin Qian

<b> Abstract: </b> Using a 1994 law change, we exploit quasi-experimental variation in the assignment of rent control in San Francisco to study its impacts on tenants and landlords. Leveraging new data tracking individuals' migration, we find rent control limits renters' mobility by 20 percent and lowers displacement from San Francisco. Landlords treated by rent control reduce rental housing supplies by 15 percent by selling to owner-occupants and redeveloping buildings. Thus, while rent control prevents displacement of incumbent renters in the short run, the lost rental housing supply likely drove up market rents in the long run, ultimately undermining the goals of the law.

#### <a href= "https://economics.mit.edu/sites/default/files/2022-08/Subsidizing%20Health%20Insurance%20for%20Low-Income%20Adults.pdf"> Subsidizing Health Insurance for Low-Income Adults: Evidence from Massachusetts </a>
#####  Amy Finkelstein, Nathaniel Hendren, and Mark Shepard

<b> Abstract: </b> How much are low-income individuals willing to pay for health insurance, and what are the implications for insurance markets? Using administrative data from Massachusetts’ subsidized insurance
exchange, we exploit discontinuities in the subsidy schedule to estimate willingness to pay and costs of insurance among low-income adults. As subsidies decline, insurance take-up falls rapidly, dropping about 25 percent for each $40 increase in monthly enrollee premiums. Marginal enrollees tend to be lower-cost, indicating adverse selection into insurance. But across the entire distribution we can observe (approximately the bottom 70 percent of the willingness to pay distribution) enrollees’ willingness to pay is always less than
half of their own expected costs that they impose on the insurer. As a result, we estimate that take-up will be highly incomplete even with generous subsidies. If enrollee premiums were 25 percent of insurers’ average costs, at most half of potential enrollees would buy insurance; even premiums subsidized to 10 percent of average costs would still leave at least 20 percent uninsured. We briefly consider potential explanations for these findings and their normative implications

## Previous Papers:

#### <a href = "https://pricetheory.uchicago.edu/levitt/Papers/JacobLevitt2003.pdf">Rotten Apples: An Investigation of the Prevalence and Predictors of Teacher Cheating</a> 
##### Brian A. Jacob and Steven D. Levitt

<b> Abstract: </b> We develop an algorithm for detecting teacher cheating that combines information on unexpected test score fluctuations and suspicious patterns of answers for students in a classroom. Using data from the Chicago public schools, we estimate that serious cases of teacher or administrator cheating on standardized tests occur in a minimum of 4–5 percent of elementary school classrooms annually. The observed frequency of cheating appears to respond strongly to relatively minor changes in incentives. Our results highlight the fact that high-powered incentive systems, especially those with bright line rules, may induce unexpected behavioral distortions such as cheating. Statistical analysis, however, may provide a means of detecting illicit acts, despite the best attempts of perpetrators to keep them clandestine.

## Suggestions of More Technical Papers:

#### <a href= "https://www.eecs.harvard.edu/cs286r/courses/spring07/papers/myerson.pdf"> Optimal Auction Design </a>
##### Roger B. Myerson

<b> Abstract: </b> This paper considers the problem faced by a seller who has a singie object to sell to one of several possible buyers, when the seller has imperfect information about how much the buyers might be willing to pay for the object. The seller's problem is to design an auction game which has a Nash equilibrium giving him the highest possible expected utility. Optimal auctions are derived in this paper for a wide class of auction design problems.


#### <a href= "https://www.cs.princeton.edu/courses/archive/spr08/cos444/papers/myerson_satterthwaite83.pdf"> Efficient Mechanisms for Bilateral Trading </a>
##### Roger B. Myerson and Mark A. Satterthwaite

<b> Abstract: </b> We consider bargaining problems between one buyer and one seller for a single object. The seller’s valuation and the buyer’s valuation for the object are assumed to be independent random variables, and each individual’s valuation is unknown to the other. We characterize the set of allocation mechanisms that are Bayesian incentive compatible and individually rational, and show the general impossibility of ex post efficient mechanisms without outside subsidies. For a wide class of problems we show how to compute mechanisms that maximize expected total gains from trade, and mechanisms that can maximize a broker’s expected profit.


#### <a href= "https://www.brown.edu/Departments/Economics/Faculty/Glenn_Loury/louryhomepage/teaching/Ec%20237/Crawford%20and%20Sobel%20(Ecta%201982).pdf"> Strategic Information Transmission </a>
##### Vincent P. Crawford and Joel Sobel

<b> Abstract: </b> This paper develops a model of strategic communication, in which a better-informed Sender (S) sends a possibly noisy signal to a Receiver (R), who then takes an action that determines the welfare of both. We characterize the set of Bayesian Nash equilibria under standard assumptions, and show that equilibrium signaling always takes a strikingly simple form, in which S partitions the support of the (scalar) variable that represents his private information and introduces noise into his signal by reporting, in effect, only which element of the partition his observation actually lies in. We show under further assumptions that before S observes his private information, the equilibrium whose partition has the greatest number of elements is Pareto-superior to all other equilibria, and that if agents coordinate on this equilibrium, R's equilibrium expected utility rises when agents' preferences become more similar. Since R bases his choice of action on rational expectations, this establishes a sense in which equilibrium signaling is more informative when agents' preferences are more similar.


#### <a href= "https://academic.oup.com/restud/article-abstract/71/1/165/1589950?redirectedFrom=fulltext"> Committee Design with Endogenous Information </a>
##### Nicola Persico

<b> Abstract: </b> Identical agents gather costly information, and then aggregate it through voting. Because information is a public good, information is underprovided relative to the social optimum. A “good” voting rule must give incentives to acquire information, as well as aggregate information efficiently. A voting rule that requires a large plurality (in the extreme, unanimity) to upset the status quo can be optimal only if the information available to each agent is sufficiently accurate. This result is independent of the preferences of voters and of the cost of information.

#### <a href= "https://www.jstor.org/stable/2951613"> Renegotiation Design with Unverifiable Information </a>
#####  Philippe Aghion, Mathias Dewatripoint, and Patrick Rey

<b> Abstract: </b> This paper considers a buyer-seller relationship with observable but unverifiable investments and/or random utility parameters. In such situations, it is known that contract renegotiation may prevent the implementation of first-best outcomes. In this paper, we show however that efficient investments and optimal risk-sharing can typically be achieved provided the initial contract is able to monitor the ex post renegotiation process. Specifically, we focus on the following two features of renegotiation design. First, default options in case renegotiation breaks down; second, the allocation of all bargaining power to either contracting party. Moreover, we show that these two features can be obtained in standard Rubinstein bargaining games through contractual provisions, such as specific-performance clauses and penalties for delay (or, equivalently, financial "hostages" refundable without interest)

#### <a href= "https://jstor.org/stable/2555911"> Option contracts and renegotiation: a solution to the hold-up problem </a>
#####  Georg Nöldeke and Klaus M. Schmidt

<b> Abstract: </b> In this article, we analyze the canonical hold-up model of Hart and Moore under the assumption that the courts can verify delivery of the good by the seller. It is shown that no further renegotiation design is necessary to achieve the first best: simple option contracts, which give the seller the right to take the delivery decision and specify payments depending on whether delivery takes place, allow implementation of efficient investment decisions and efficient trade.

#### <a href= "https://arxiv.org/pdf/1811.03579"> Mechanism Design with Limited Commitment* </a>
#####  Laura Doval and Vasiliki Skreta

<b> Abstract: </b> We develop a tool akin to the revelation principle for dynamic mechanism-selection
games in which the designer can only commit to short-term mechanisms. We identify a canonical class of mechanisms rich enough to replicate the outcomes of any equilibrium in a mechanism-selection game between an uninformed designer and a privately informed agent. A cornerstone of our methodology is the idea that a mechanism should encode not only the rules that determine the allocation, but also the information the designer obtains from the interaction with the agent. Therefore, how much the designer learns, which is the key tension in design with limited commitment, becomes an explicit part of the design. Our result simplifies the search for the designer-optimal outcome by reducing the agent’s behavior to a series of participation, truthtelling, and
Bayes’ plausibility constraints the mechanisms must satisfy.

#### <a href= "https://ipl.econ.duke.edu/seminars/system/files/seminars/1090.pdf"> Uninsured Idiosyncratic Risk and Aggregate Saving </a>
##### S. Rao Aiyagari 

<b> Abstract: </b> We present a qualitative and quantitative analysis of the standard growth model modified to include precautionary saving motives and liquidity constraints. We address the impact on the aggregate saving rate, the importance of asset trading to individuals, and the relative inequality of wealth and income distributions.

#### <a href= "https://pages.stern.nyu.edu/~xgabaix/papers/granular.pdf"> The Granular Origins of Aggregate Fluctuations </a>
##### Xavier Gabaix 

<b> Abstract: </b> This paper proposes that idiosyncratic firm-level shocks can explain an important
part of aggregate movements and provide a microfoundation for aggregate shocks. Existing research has focused on using aggregate shocks to explain business cycles, arguing that individual firm shocks average out in the aggregate. I show that this argument breaks down if the distribution of firm sizes is fat-tailed, as documented empirically. The idiosyncratic movements of the largest 100 firms in the United States appear to explain about one-third of variations in output growth. This “granular” hypothesis suggests new directions for macroeconomic research, in particular that macroeconomic questions can be clarified by looking at the behavior of large firms. This paper’s ideas and analytical results may also be useful for thinking about the fluctuations of other
economic aggregates, such as exports or the trade balance

#### <a href= "https://www-users.york.ac.uk/~psm509/ULB2012/KiyotakiMooreJPE1997.pdf"> Credit Cycles </a>
##### Nobuhiro Kiyotaki and John Moore

<b> Abstract: </b> We construct a model of a dynamic economy in which lenders cannot force borrowers to repay their debts unless the debts are secured. In such an economy, durable assets play a dual role: not only are they factors of production, but they also serve as collateral for loans. The dynamic interaction between credit limits and asset prices turns out to be a powerful transmission mechanism by which the effects of shocks persist, amplify, and spill over to other sectors. We show that small, temporary shocks to technology or income distribution can generate large, persistent fluctuations in output and asset prices.

#### <a href= "https://arxiv.org/pdf/1712.04802"> Fisher-schultz Lecture: Generic Machine Learning Inference On Heterogenous Treatment Effects In Randomized Experiments, With An Application To Immunization In India </a>
##### Victor Chernozhukov, Mert Demirer, Esther Duflo, and Ivan Fernandez-val 

<b> Abstract: </b> We propose strategies to estimate and make inference on key features of heterogeneous
effects in randomized experiments. These key features include best linear predictors of the effects
using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high dimensional settings, where
the effects are proxied (but not necessarily consistently estimated) by predictive and causal machine
learning methods. We post-process these proxies into estimates of the key features. Our approach
is generic, it can be used in conjunction with penalized methods, neural networks, random forests,
boosted trees, and ensemble methods, both predictive and causal. Estimation and inference are based
on repeated data splitting to avoid overfitting and achieve validity. We use quantile aggregation of
the results across many potential splits, in particular taking medians of p-values and medians and
other quantiles of confidence intervals. We show that quantile aggregation lowers estimation risks
over a single split procedure, and establish its principal inferential properties. Finally, our analysis
reveals ways to build provably better machine learning proxies through causal learning: we can use
the objective functions that we develop to construct the best linear predictors of the effects, to obtain
better machine learning proxies in the initial step. We illustrate the use of both inferential tools
and causal learners with a randomized field experiment that evaluates a combination of nudges to
stimulate demand for immunization in India

#### <a href= "https://watermark.silverchair.com/ectj00c1.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA0wwggNIBgkqhkiG9w0BBwagggM5MIIDNQIBADCCAy4GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMVTRdphOh9lhki8IWAgEQgIIC_5BfSRHz8C8Ahu9jzEhkhsGmR16Bx15SMN39wb106S0VCxtBXVum1YdKUfWSRuVQc11n880LlGJfLmHybDwcIwOXwJJA6gaUi6jG1X1kCBIqBZ3fvkzyq-B8_FfrPALVLdBEplZRj_y-oL1STE40xCwv_dBal3mAhLMIPw1Epj6Fh4DdciioGtbmz-1WzOp8_JKqjnOVBvrB6bqMxLSfL0Pu9jRHmxvmAjFb4P94zwDflXFpccJT-pLV6lU9J-BDh7a-yeXHFb36m0t3qslOtQkCYF7MPb-z4ZPjdXprsz0GmCxNtkVRn9GbItWW1yQC4d2HxjpXlljSWb8kvEWGekgHVSPVfZmSXjkN7jZKsHKxDnyl9Hl-l9SNDGoD-Hy-mGJsR2Zss28dort5FL3CEAI4wqYwjAd1vY2MeU7sX1u04cWm3skH5Yfn3DOhL61jLrYfjQ_qdZzLpYNsDCazkqUQWUcpPvy00rZfCG6sa57LWKdlrQxwuoQp0CK6s7xv_5azplLTigYuKz7cANFbxRIedeeFoNvyFtYAxStAbz6dv96ALynOOrNXytcESJxM2zCYjPF8LzYdOkwWwO3OYRRV1hfTRGXMgf2fshldcbAr8LqFDXUecvF-vv453IUbDjexhDNM_CQ4tzr0EeVcbwIQ1xG7ei5RNem4gf9-0Jopp2Cz8S-2ngmajeDUAvGMq12yhqOHgMB8rPQRB0Cwm2Y3JHvtFWuOkZsQbkAMdHjlazVfeLxszngnp9eKy83CTnNS3CLVZQblmazFUFRECNsQ1NersNNXPXK-C6KAxz8z_Zv7Wrj40ZNRc5kc8tJmFrgB6nW3I6LW4_iwLdP520qXpGU1rmjdawn7VwXqucJdT_GO6pwoi7Cgi85ndlzCOKz8Rfx2Qjy-QgIKvj68gC92WvsT9tUK_XkkYDmv-CXUYirdCMFJtSm7b2igIiIiKNb3NqBAkdOtR-IYq5cGmjcfRnoW_HGuwOzoLusoTfFVNfDEeJVn7MugxkA9Uiub"> Double/debiased machine learning for treatment and structural parameters </a>
##### Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins 

<b> Abstract: </b> We revisit the classic semi-parametric problem of inference on a low-dimensional
parameter θ0 in the presence of high-dimensional nuisance parameters η0. We depart from the
classical setting by allowing for η0 to be so high-dimensional that the traditional assumptions
(e.g. Donsker properties) that limit complexity of the parameter space for this object break
down. To estimate η0, we consider the use of statistical or machine learning (ML) methods,
which are particularly well suited to estimation in modern, very high-dimensional cases.
ML methods perform well by employing regularization to reduce variance and trading
off regularization bias with overfitting in practice. However, both regularization bias and
overfitting in estimating η0 cause a heavy bias in estimators of θ0 that are obtained by
naively plugging ML estimators of η0 into estimating equations for θ0. This bias results in
the naive estimator failing to be N−1/2 consistent, where N is the sample size. We show that
the impact of regularization bias and overfitting on estimation of the parameter of interest θ0
can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal
moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate
θ0; (2) making use of cross-fitting, which provides an efficient form of data-splitting. We
call the resulting set of methods double or debiased ML (DML). We verify that DML
delivers point estimators that concentrate in an N−1/2-neighbourhood of the true parameter
values and are approximately unbiased and normally distributed, which allows construction
of valid confidence statements. The generic statistical theory of DML is elementary and
simultaneously relies on only weak theoretical requirements, which will admit the use of a
broad array of modern ML methods for estimating the nuisance parameters, such as random
forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of
these methods. We illustrate the general theory by applying it to provide theoretical properties
of the following: DML applied to learn the main regression parameter in a partially linear
regression model; DML applied to learn the coefficient on an endogenous variable in a
partially linear instrumental variables model; DML applied to learn the average treatment
effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.

#### <a href= "https://openaccess.nhh.no/nhh-xmlui/bitstream/handle/11250/2652016/0120.pdf?sequence=1"> The Triple Difference Estimator </a>
##### Andreas Olden and Jarle Moen
<b> Abstract: </b> Triple difference has become a widely used estimator in empirical work. A close reading
of articles in top economics journals reveals that the use of the estimator to a large
extent rests on intuition. The identifying assumptions are neither formally derived nor
generally agreed on. We give a complete presentation of the triple difference estimator,
and show that even though the estimator can be computed as the difference between two
difference-in-differences estimators, it does not require two parallel trend assumptions
to have a causal interpretation. The reason is that the difference between two biased
difference-in-differences estimators will be unbiased as long as the bias is the
